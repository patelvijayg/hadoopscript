new VM
checkout 
. ./alias.txt 
.checkout 
./install_setup_variable.sh 
.resetalias

https://github.com/apache/spark/tree/v2.3.1


reset entire dfs system. (before run this please stophdall)
$SCRIPT_DIR/reset_factory.sh

if some changs in hadoop config file then change it as script folder and then run it
$SCRIPT_DIR/copy_files_on_master.sh

after change run this to sync with all the nodes from master hadoop conf dir
$SCRIPT_DIR/syncnode.sh  


$SCRIPT_DIR/unittest.sh

git reset --hard FETCH_HEAD
git pull

step to prepare.
mv /home/vagrant/scripts /home/vagrant/old_scripts
sudo chown -R vagrant:vagrant $HADOOP_HOME/
sudo chown -R vagrant:vagrant $SPARK_HOME/

MAKE NOTE : logout or open other session.

./copy_files_on_master.sh 
./syncnode.sh 
./reset_factory.sh 
starthdall 
./unittest.sh 


git config --global user.email "patelvijayg@gmail.com"
git clone https://github.com/patelvijayg/hadoopscript.git /home/vagrant/scripts

git commit -m "added execute permission"
git push

ln -s /usr/kafka_2.11-2.0.0 /usr/kafka